# Exercise 2 - Transform data using notebooks and Spark clusters 

Timebox: 50 minutes

# Context


%TODO STORY


1. Create a notebook 
2. Load data from Lakehouse tables into Spark DataFrames 
3. Transform the data using SQL and PySpark APIs 
4. Write the transformed data back to Lakehouse tables or other storage formats 
5. Visualize and interact with the data using charts and widgets 
6. Save and run the notebook as a job 
7. WS-level settings overview 

 

## Task 1
### Objective
### Definition of done


## Task 2
### Objective
### Definition of done



# Definition of done (and you can go to the next exercise)